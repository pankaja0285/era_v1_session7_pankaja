{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkdivya/EVA/blob/main/5_CodingDrillDown/Experiments/MNIST_Step%201_BasicSkeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cWqKnCsCZ09b"
      },
      "source": [
        "### Target:\n",
        "\n",
        "- Establish the basic skeleton in terms of convolution and placement of transition blocks such as max pooling, 1x1's\n",
        "- Attempting to reduce the number of parameters as low as possible\n",
        "- Adding GAP and remove the last BIG kernel.\n",
        "\n",
        "### Results:\n",
        "- Total parameters: 4572\n",
        "- Best Training accuracy: 98.22\n",
        "- Best Test accuracy: 98.43\n",
        "\n",
        "### Analysis:\n",
        "- Structured the model as a new model class \n",
        "- The model is lighter with less number of parameters \n",
        "- The performace is reduced compared to previous models. Since we have reduced model capacity, this is expected, the model has capability to learn.   \n",
        "- Next, we will be tweaking this model further and increase the capacity to push it more towards the desired accuracy."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "# for visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model import Model_2, download_model_data, create_data_loader, train_and_predict\n",
        "from utils import get_device, plot_metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n",
        "\n",
        "Here is the list of all the transformations which come pre-built with PyTorch\n",
        "\n",
        "1.   Compose\n",
        "2.   ToTensor\n",
        "3.   ToPILImage\n",
        "4. Normalize\n",
        "5. Resize\n",
        "6. Scale\n",
        "7. CenterCrop\n",
        "8. Pad\n",
        "9. Lambda\n",
        "10. RandomApply\n",
        "11. RandomChoice\n",
        "12. RandomOrder\n",
        "13. RandomCrop\n",
        "14. RandomHorizontalFlip\n",
        "15. RandomVerticalFlip\n",
        "16. RandomResizedCrop\n",
        "17. RandomSizedCrop\n",
        "18. FiveCrop\n",
        "19. TenCrop\n",
        "20. LinearTransformation\n",
        "21. ColorJitter\n",
        "22. RandomRotation\n",
        "23. RandomAffine\n",
        "24. Grayscale\n",
        "25. RandomGrayscale\n",
        "26. RandomPerspective\n",
        "27. RandomErasing\n",
        "\n",
        "You can read more about them [here](https://pytorch.org/docs/stable/_modules/torchvision/transforms/transforms.html)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Prepare Dataset\n",
        "\n",
        "MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels\n",
        "\n",
        "We load the PIL images using torchvision.datasets.MNIST, while loading the image we transform he data to tensor and normalize the images with mean and std deviation of MNIST images.\n",
        "\n",
        "Data tasks:\n",
        "- transformers\n",
        "- data download\n",
        "- train and test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YtssFUKb-jqx"
      },
      "outputs": [],
      "source": [
        "\n",
        "ds_train, ds_test = download_model_data()\n",
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "kw_args = dict(shuffle=True, batch_size=128, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(ds_train, **kw_args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFjoFekE_va"
      },
      "source": [
        "# Data Statistics\n",
        "\n",
        "It is important to know your data very well. Let's check some of the statistics around our data and how it actually looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "hWZPPo3yEHDW",
        "outputId": "01df55f3-0946-4afc-a51f-9cc0ef24a8c0"
      },
      "outputs": [],
      "source": [
        "# We'd need to convert it into Numpy! Remember above we have converted it into tensors already\n",
        "train_data = ds_train.train_data\n",
        "train_data = ds_train.transform(train_data.numpy())\n",
        "\n",
        "print('[Train]')\n",
        "print(' - Numpy Shape:', ds_train.train_data.cpu().numpy().shape)\n",
        "print(' - Tensor Shape:', ds_train.train_data.size())\n",
        "print(' - min:', torch.min(train_data))\n",
        "print(' - max:', torch.max(train_data))\n",
        "print(' - mean:', torch.mean(train_data))\n",
        "print(' - std:', torch.std(train_data))\n",
        "print(' - var:', torch.var(train_data))\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# visualize\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7l9lNaWYKuik"
      },
      "source": [
        "## MORE\n",
        "\n",
        "It is important that we view as many images as possible. This is required to get some idea on image augmentation later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "hXXAg8hbK16u",
        "outputId": "611605c3-1f36-4201-efba-eea182592e1c"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h"
      },
      "source": [
        "# Model_2 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "### Model_2 summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skB97zIJQQe",
        "outputId": "83ed714c-0299-4ded-dbbf-812e922e8ca9"
      },
      "outputs": [],
      "source": [
        "# get device and load Model_2\n",
        "device = get_device()\n",
        "print(device)\n",
        "model = Model_2().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "### Train and test -  Model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fbkF2nN_LYIb"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "# load model to device and start the training \n",
        "model = Model_2().to(device)\n",
        "epochs = 15\n",
        "train_losses2, train_acc2, test_losses2, test_acc2 = train_and_predict(model, device,\n",
        "                                                                   train_loader=train_loader,\n",
        "                                                                   test_loader=test_loader, \n",
        "                                                                   num_epochs=epochs, lr=0.01)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plot the train and test losses and accuracies for Model_2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_metrics(train_losses2, train_acc2, test_losses2, test_acc2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "MNIST_Step 1_BasicSkeleton.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
